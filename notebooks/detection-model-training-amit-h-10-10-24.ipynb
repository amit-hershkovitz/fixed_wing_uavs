{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9595969,"sourceType":"datasetVersion","datasetId":5836850}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics --quiet\n!pip install -U ipywidgets --quiet","metadata":{"execution":{"iopub.status.busy":"2024-10-10T17:42:23.790351Z","iopub.execute_input":"2024-10-10T17:42:23.791459Z","iopub.status.idle":"2024-10-10T17:42:37.212335Z","shell.execute_reply.started":"2024-10-10T17:42:23.791406Z","shell.execute_reply":"2024-10-10T17:42:37.211018Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nfrom distutils.dir_util import copy_tree\n\nfrom ultralytics.data.utils import autosplit\nfrom ultralytics import YOLO","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy train images from kaggle input directory to kaggle output directory\ndataset_source_dir = '/kaggle/input/fixed-wing-uavs/dataset-07-10-2024/'\ndataset_target_dir = '/kaggle/working/dataset/'\n\ndata_yaml_source_path = '/kaggle/working/dataset/data_kaggle.yaml'\ndata_yaml_target_path = '/kaggle/working/data_kaggle.yaml'\n\nos.makedirs(dataset_target_dir, exist_ok=True)\ncopy_tree(dataset_source_dir, dataset_target_dir)\nshutil.move(data_yaml_source_path, data_yaml_target_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T17:41:24.588667Z","iopub.execute_input":"2024-10-10T17:41:24.589407Z","iopub.status.idle":"2024-10-10T17:41:26.564187Z","shell.execute_reply.started":"2024-10-10T17:41:24.589367Z","shell.execute_reply":"2024-10-10T17:41:26.563160Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/data_kaggle.yaml'"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Split Data to ","metadata":{}},{"cell_type":"code","source":"autosplit(path=\"/kaggle/working/dataset\", weights = (0.8, 0.05, 0.05))","metadata":{"execution":{"iopub.status.busy":"2024-10-10T17:42:47.687495Z","iopub.execute_input":"2024-10-10T17:42:47.687927Z","iopub.status.idle":"2024-10-10T17:42:51.873145Z","shell.execute_reply.started":"2024-10-10T17:42:47.687883Z","shell.execute_reply":"2024-10-10T17:42:51.872041Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nAutosplitting images from /kaggle/working/dataset\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 891/891 [00:00<00:00, 16963.18it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"model = YOLO(\"yolo11n.pt\")\nresults = model.train(data=\"/kaggle/working/data.yaml\", epochs=3)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T20:01:04.733866Z","iopub.execute_input":"2024-10-09T20:01:04.734760Z","iopub.status.idle":"2024-10-09T20:02:48.724798Z","shell.execute_reply.started":"2024-10-09T20:01:04.734715Z","shell.execute_reply":"2024-10-09T20:02:48.723877Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nUltralytics 8.3.9 üöÄ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 23.6MB/s]\n2024-10-09 20:01:10,907\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-10-09 20:01:11,770\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nYOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n\nTransferred 448/499 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train7', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111395681110581, max=1.0)‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ef8edbf65eb463cbf1453c36a84fd0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241009_200139-0rvwvfuq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics/runs/0rvwvfuq' target=\"_blank\">train7</a></strong> to <a href='https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics' target=\"_blank\">https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics/runs/0rvwvfuq' target=\"_blank\">https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics/runs/0rvwvfuq</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset... 590 images, 132 backgrounds, 1 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 723/723 [00:00<00:00, 986.07it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/dataset/517.jpg: ignoring corrupt image/label: cannot identify image file '/kaggle/working/dataset/517.jpg'\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset... 69 images, 9 backgrounds, 1 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:00<00:00, 1539.19it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/dataset/8.jpg: ignoring corrupt image/label: cannot identify image file '/kaggle/working/dataset/8.jpg'\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train7/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train7\u001b[0m\nStarting training for 3 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/3      2.64G      1.251        2.4      1.455          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:11<00:00,  4.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.77it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         78         82      0.705     0.0488      0.347      0.168\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/3      2.66G      1.368      1.973      1.501          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:09<00:00,  4.68it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  7.16it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         78         82       0.43      0.341      0.362        0.2\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/3      2.65G      1.274      1.959      1.457          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:09<00:00,  4.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         78         82      0.788      0.636      0.727      0.381\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n3 epochs completed in 0.012 hours.\nOptimizer stripped from runs/detect/train7/weights/last.pt, 5.5MB\nOptimizer stripped from runs/detect/train7/weights/best.pt, 5.5MB\n\nValidating runs/detect/train7/weights/best.pt...\nUltralytics 8.3.9 üöÄ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all         78         82      0.788      0.636      0.728      0.381\nSpeed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 2.0ms postprocess per image\nResults saved to \u001b[1mruns/detect/train7\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='10.227 MB of 10.227 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ‚ñà‚ñÇ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ‚ñà‚ñÇ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ‚ñà‚ñÇ</td></tr><tr><td>metrics/mAP50(B)</td><td>‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>metrics/mAP50-95(B)</td><td>‚ñÅ‚ñÇ‚ñà</td></tr><tr><td>metrics/precision(B)</td><td>‚ñÜ‚ñÅ‚ñà</td></tr><tr><td>metrics/recall(B)</td><td>‚ñÅ‚ñÑ‚ñà</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/box_loss</td><td>‚ñÅ‚ñà‚ñÇ</td></tr><tr><td>train/cls_loss</td><td>‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>train/dfl_loss</td><td>‚ñÅ‚ñà‚ñÅ</td></tr><tr><td>val/box_loss</td><td>‚ñÇ‚ñà‚ñÅ</td></tr><tr><td>val/cls_loss</td><td>‚ñà‚ñá‚ñÅ</td></tr><tr><td>val/dfl_loss</td><td>‚ñÉ‚ñà‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00068</td></tr><tr><td>lr/pg1</td><td>0.00068</td></tr><tr><td>lr/pg2</td><td>0.00068</td></tr><tr><td>metrics/mAP50(B)</td><td>0.72757</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.38129</td></tr><tr><td>metrics/precision(B)</td><td>0.7884</td></tr><tr><td>metrics/recall(B)</td><td>0.63617</td></tr><tr><td>model/GFLOPs</td><td>6.441</td></tr><tr><td>model/parameters</td><td>2590035</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>3.818</td></tr><tr><td>train/box_loss</td><td>1.27421</td></tr><tr><td>train/cls_loss</td><td>1.95941</td></tr><tr><td>train/dfl_loss</td><td>1.45677</td></tr><tr><td>val/box_loss</td><td>1.42857</td></tr><tr><td>val/cls_loss</td><td>1.94286</td></tr><tr><td>val/dfl_loss</td><td>1.76532</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">train7</strong> at: <a href='https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics/runs/0rvwvfuq' target=\"_blank\">https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics/runs/0rvwvfuq</a><br/> View project at: <a href='https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics' target=\"_blank\">https://wandb.ai/amit-hershkovitz-technion-israel-institute-of-technology/Ultralytics</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 21 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241009_200139-0rvwvfuq/logs</code>"},"metadata":{}}]}]}